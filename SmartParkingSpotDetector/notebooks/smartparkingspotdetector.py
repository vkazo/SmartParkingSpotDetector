# -*- coding: utf-8 -*-
"""SmartParkingSpotDetector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oU7fmno-UHBVuozZxdBnuaRKmWMEkIip
"""

# Smart Parking Spot Detector - Complete Implementation
# Student: Kaden Glover | Course: ITAI 1378
# This code trains YOLOv8 to detect cars and count available parking spots

# ============================================================================
# PART 1: SETUP AND INSTALLATION
# ============================================================================

# Install required packages
!pip install -q ultralytics opencv-python pillow

# Import libraries
from ultralytics import YOLO
import cv2
import os
from pathlib import Path
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import torch

# Configure matplotlib for better display
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 100

# Check GPU availability
print("="*70)
print("SYSTEM CONFIGURATION")
print("="*70)
print(f"GPU Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU Device: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    DEVICE = 0
else:
    print("‚ö†Ô∏è  GPU not available - using CPU (training will be slower)")
    DEVICE = 'cpu'
print("="*70 + "\n")

# ============================================================================
# PART 2: DOWNLOAD AND SETUP DATASET
# ============================================================================

import kagglehub

print("üì• Downloading dataset from Kaggle...")
dataset_path = kagglehub.dataset_download('braunge/aerial-view-car-detection-for-yolov5')
print(f"‚úì Dataset downloaded to: {dataset_path}\n")

# Explore dataset structure
print("üìÇ Dataset Structure:")
for root, dirs, files in os.walk(dataset_path):
    level = root.replace(dataset_path, '').count(os.sep)
    if level < 3:  # Only show first 3 levels
        indent = '  ' * level
        folder_name = os.path.basename(root) or 'Root'
        print(f"{indent}üìÅ {folder_name}/")
        if level < 2:
            subindent = '  ' * (level + 1)
            img_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            txt_files = [f for f in files if f.lower().endswith('.txt')]
            if img_files:
                print(f"{subindent}üì∑ {len(img_files)} images")
            if txt_files:
                print(f"{subindent}üìù {len(txt_files)} labels")

DATASET_BASE = dataset_path

# ============================================================================
# PART 3: AUTO-DETECT DATASET PATHS
# ============================================================================

print("\nüîç Auto-detecting dataset paths...")

train_imgs = None
val_imgs = None

# Search for image folders
for root, dirs, files in os.walk(DATASET_BASE):
    for subdir in ['train', 'images/train', 'train/images']:
        check_path = os.path.join(root, subdir)
        if os.path.exists(check_path):
            img_files = [f for f in os.listdir(check_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            if len(img_files) > 0:
                train_imgs = check_path
                for val_name in ['val', 'valid', 'test']:
                    val_path = check_path.replace('train', val_name)
                    if os.path.exists(val_path):
                        val_imgs = val_path
                        break
                break
    if train_imgs:
        break

if train_imgs and val_imgs:
    train_count = len([f for f in os.listdir(train_imgs) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    val_count = len([f for f in os.listdir(val_imgs) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

    print(f"‚úì Training images: {train_imgs}")
    print(f"  ‚Üí {train_count} images")
    print(f"‚úì Validation images: {val_imgs}")
    print(f"  ‚Üí {val_count} images")

    train_labels = train_imgs.replace('images', 'labels')
    val_labels = val_imgs.replace('images', 'labels')

    if os.path.exists(train_labels):
        print(f"‚úì Training labels: {train_labels}")
    if os.path.exists(val_labels):
        print(f"‚úì Validation labels: {val_labels}")
else:
    raise Exception("Could not find dataset folders. Please check the dataset structure.")

# Create YAML configuration
data_yaml_content = f"""train: {train_imgs}
val: {val_imgs}

nc: 1
names: ['car']
"""

with open('mydata.yaml', 'w') as f:
    f.write(data_yaml_content)

print("\n‚úì Created mydata.yaml configuration\n")

# ============================================================================
# PART 4: VISUALIZE DATASET SAMPLES
# ============================================================================

def visualize_samples(image_folder, label_folder, num_samples=5):
    """Display sample images with bounding boxes"""

    image_files = list(Path(image_folder).glob('*'))[:num_samples]
    if not image_files:
        print(f"No images found in {image_folder}")
        return

    num_cols = min(len(image_files), num_samples)
    fig, axes = plt.subplots(1, num_cols, figsize=(5*num_cols, 5))
    if num_cols == 1:
        axes = [axes]

    for idx, img_path in enumerate(image_files):
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        label_path = Path(label_folder) / (img_path.stem + '.txt')

        if label_path.exists():
            with open(label_path, 'r') as f:
                lines = f.readlines()

            h, w = img.shape[:2]

            for line in lines:
                parts = line.strip().split()
                if len(parts) == 5:
                    _, x_center, y_center, width, height = map(float, parts)
                    x1 = int((x_center - width/2) * w)
                    y1 = int((y_center - height/2) * h)
                    x2 = int((x_center + width/2) * w)
                    y2 = int((y_center + height/2) * h)
                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)

        axes[idx].imshow(img)
        axes[idx].axis('off')
        axes[idx].set_title(f'Training Sample {idx+1}', fontsize=12, fontweight='bold')

    plt.suptitle('Dataset Samples with Ground Truth Labels', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.show()

print("="*70)
print("üì∏ DATASET VISUALIZATION")
print("="*70 + "\n")

if train_imgs and os.path.exists(train_imgs):
    train_labels_path = train_imgs.replace('images', 'labels')
    if os.path.exists(train_labels_path):
        visualize_samples(train_imgs, train_labels_path, num_samples=5)
    else:
        print(f"Label folder not found: {train_labels_path}")
else:
    print("Training images folder not found")

# ============================================================================
# PART 5: TRAIN YOLOV8 MODEL
# ============================================================================

def train_model(epochs=50, img_size=640, batch_size=16):
    """Train YOLOv8 model on parking dataset"""

    print("\n" + "="*70)
    print("üöÄ STARTING MODEL TRAINING")
    print("="*70)
    print(f"Configuration:")
    print(f"  ‚Ä¢ Model: YOLOv8 Nano (fastest)")
    print(f"  ‚Ä¢ Epochs: {epochs}")
    print(f"  ‚Ä¢ Image size: {img_size}x{img_size}")
    print(f"  ‚Ä¢ Batch size: {batch_size}")
    print(f"  ‚Ä¢ Device: {DEVICE}")
    print(f"  ‚Ä¢ Estimated time: 20-40 minutes on GPU")
    print("="*70 + "\n")

    model = YOLO('yolov8n.pt')

    results = model.train(
        data='mydata.yaml',
        epochs=epochs,
        imgsz=img_size,
        batch=batch_size,
        device=DEVICE,
        patience=10,
        save=True,
        project='parking_runs',
        name='parking_detector',
        exist_ok=True,
        verbose=True
    )

    print("\n" + "="*70)
    print("‚úÖ TRAINING COMPLETE!")
    print("="*70)
    print(f"Model saved: parking_runs/parking_detector/weights/best.pt")
    print("="*70 + "\n")

    return model

print("‚è≥ Training in progress... This will take 20-40 minutes")
trained_model = train_model(epochs=50, img_size=640, batch_size=16)

# ============================================================================
# PART 6: VALIDATE MODEL PERFORMANCE
# ============================================================================

def validate_model(model_path='parking_runs/parking_detector/weights/best.pt'):
    """Evaluate model on validation set"""

    print("\n" + "="*70)
    print("üìä VALIDATING MODEL PERFORMANCE")
    print("="*70 + "\n")

    model = YOLO(model_path)
    metrics = model.val(data='mydata.yaml')

    # Extract metrics safely
    map50 = float(metrics.box.map50) if hasattr(metrics.box.map50, '__float__') else float(metrics.box.map50.mean())
    map_overall = float(metrics.box.map) if hasattr(metrics.box.map, '__float__') else float(metrics.box.map.mean())
    precision = float(metrics.box.p) if hasattr(metrics.box.p, '__float__') else float(metrics.box.p.mean())
    recall = float(metrics.box.r) if hasattr(metrics.box.r, '__float__') else float(metrics.box.r.mean())

    print("PERFORMANCE METRICS")
    print("="*70)
    print(f"mAP@50:      {map50:.3f}  {'‚úÖ Excellent!' if map50 > 0.7 else '‚ö†Ô∏è  Good' if map50 > 0.6 else '‚ùå Needs work'}")
    print(f"mAP@50-95:   {map_overall:.3f}")
    print(f"Precision:   {precision:.3f}  (How accurate are detections)")
    print(f"Recall:      {recall:.3f}  (% of cars found)")
    print("="*70)

    if map50 > 0.70:
        print("\n‚úÖ EXCELLENT: Model exceeds target accuracy!")
    elif map50 > 0.60:
        print("\n‚ö†Ô∏è  GOOD: Model works well, consider more training for improvement")
    else:
        print("\n‚ùå NEEDS IMPROVEMENT: Try more epochs or data augmentation")

    print("="*70 + "\n")
    return metrics

validation_metrics = validate_model()

# ============================================================================
# PART 7: PARKING SPOT COUNTER CLASS
# ============================================================================

class ParkingSpotCounter:
    """Detects cars and calculates available parking spots"""

    def __init__(self, model_path, total_spots=50):
        self.model = YOLO(model_path)
        self.total_spots = total_spots
        print(f"‚úì Parking counter initialized ({total_spots} total spots)")

    def detect_cars(self, image_path, conf_threshold=0.5):
        """Detect cars in an image"""
        results = self.model(image_path, conf=conf_threshold, verbose=False)
        car_count = len(results[0].boxes)
        return results, car_count

    def calculate_available_spots(self, car_count):
        """Calculate available parking spots"""
        return max(0, self.total_spots - car_count)

    def visualize_detection(self, image_path, conf_threshold=0.5):
        """Detect cars and visualize results"""

        results, car_count = self.detect_cars(image_path, conf_threshold)
        available_spots = self.calculate_available_spots(car_count)

        # Get annotated image
        annotated_img = results[0].plot()
        h, w = annotated_img.shape[:2]

        # Add professional info overlay
        overlay = annotated_img.copy()
        cv2.rectangle(overlay, (10, 10), (450, 120), (0, 0, 0), -1)
        annotated_img = cv2.addWeighted(annotated_img, 0.7, overlay, 0.3, 0)

        cv2.rectangle(annotated_img, (10, 10), (450, 120), (255, 255, 255), 2)
        cv2.putText(annotated_img, f"Cars Detected: {car_count}",
                    (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
        cv2.putText(annotated_img, f"Available Spots: {available_spots}",
                    (20, 95), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        # Display
        plt.figure(figsize=(14, 10))
        plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.title(f"Detection Result: {car_count} Cars, {available_spots} Spots Available",
                  fontsize=16, fontweight='bold', pad=15)
        plt.tight_layout()
        plt.show()

        return {
            'cars_detected': car_count,
            'available_spots': available_spots,
            'total_spots': self.total_spots,
            'occupancy_rate': (car_count / self.total_spots) * 100
        }

# ============================================================================
# PART 8: TEST ON SINGLE IMAGE
# ============================================================================

print("="*70)
print("üß™ TESTING THE PARKING DETECTOR")
print("="*70 + "\n")

counter = ParkingSpotCounter(
    model_path='parking_runs/parking_detector/weights/best.pt',
    total_spots=50
)

if val_imgs and os.path.exists(val_imgs):
    val_image_files = list(Path(val_imgs).glob('*'))
    if val_image_files:
        test_image = str(val_image_files[0])
        print(f"Testing on: {Path(test_image).name}\n")

        results = counter.visualize_detection(test_image, conf_threshold=0.5)

        print("\n" + "="*70)
        print("PARKING LOT STATUS")
        print("="*70)
        print(f"üöó Cars Detected:     {results['cars_detected']}")
        print(f"üÖøÔ∏è  Available Spots:   {results['available_spots']}")
        print(f"üìä Total Capacity:    {results['total_spots']}")
        print(f"üìà Occupancy Rate:    {results['occupancy_rate']:.1f}%")
        print("="*70 + "\n")

# ============================================================================
# PART 9: BATCH TESTING WITH VISUALIZATIONS
# ============================================================================

def test_multiple_images(counter, image_folder, num_images=10):
    """Test detector on multiple images and show comprehensive results"""

    image_files = list(Path(image_folder).glob('*'))[:num_images]

    if not image_files:
        print(f"No images found in {image_folder}")
        return []

    print("\n" + "="*70)
    print(f"üì∏ BATCH TESTING ON {len(image_files)} IMAGES")
    print("="*70 + "\n")

    all_results = []

    for idx, img_path in enumerate(image_files, 1):
        print(f"\n{'='*70}")
        print(f"IMAGE {idx}/{len(image_files)}: {img_path.name}")
        print('='*70)

        results = counter.visualize_detection(str(img_path))

        print(f"\nüìä Results:")
        print(f"   üöó Cars: {results['cars_detected']}")
        print(f"   üÖøÔ∏è  Available: {results['available_spots']}")
        print(f"   üìà Occupancy: {results['occupancy_rate']:.1f}%")

        all_results.append(results)

    # Summary statistics
    print("\n" + "="*70)
    print("üìä BATCH TESTING SUMMARY")
    print("="*70)

    total_cars = sum(r['cars_detected'] for r in all_results)
    avg_occupancy = sum(r['occupancy_rate'] for r in all_results) / len(all_results)
    min_cars = min(r['cars_detected'] for r in all_results)
    max_cars = max(r['cars_detected'] for r in all_results)

    print(f"Images Tested:        {len(image_files)}")
    print(f"Total Cars Found:     {total_cars}")
    print(f"Average Occupancy:    {avg_occupancy:.1f}%")
    print(f"Range:                {min_cars} - {max_cars} cars per image")
    print("="*70 + "\n")

    # Create summary charts
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # Cars detected chart
    car_counts = [r['cars_detected'] for r in all_results]
    colors1 = ['#2E86AB' if c < 35 else '#A23B72' if c < 45 else '#F18F01' for c in car_counts]
    ax1.bar(range(1, len(car_counts)+1), car_counts, color=colors1, edgecolor='black', linewidth=1.5)
    ax1.set_xlabel('Image Number', fontsize=13, fontweight='bold')
    ax1.set_ylabel('Cars Detected', fontsize=13, fontweight='bold')
    ax1.set_title('Cars Detected Per Image', fontsize=15, fontweight='bold', pad=15)
    ax1.grid(axis='y', alpha=0.3, linestyle='--')
    ax1.set_axisbelow(True)

    # Occupancy rate chart
    occupancy_rates = [r['occupancy_rate'] for r in all_results]
    colors2 = ['#06A77D' if o < 70 else '#F4B942' if o < 90 else '#D62246' for o in occupancy_rates]
    ax2.bar(range(1, len(occupancy_rates)+1), occupancy_rates, color=colors2, edgecolor='black', linewidth=1.5)
    ax2.set_xlabel('Image Number', fontsize=13, fontweight='bold')
    ax2.set_ylabel('Occupancy Rate (%)', fontsize=13, fontweight='bold')
    ax2.set_title('Parking Lot Occupancy Analysis', fontsize=15, fontweight='bold', pad=15)
    ax2.axhline(y=70, color='#F4B942', linestyle='--', linewidth=2, label='70% Capacity', alpha=0.7)
    ax2.axhline(y=90, color='#D62246', linestyle='--', linewidth=2, label='90% Full', alpha=0.7)
    ax2.legend(fontsize=11)
    ax2.grid(axis='y', alpha=0.3, linestyle='--')
    ax2.set_axisbelow(True)
    ax2.set_ylim(0, 100)

    plt.tight_layout()
    plt.show()

    return all_results

if val_imgs and os.path.exists(val_imgs):
    test_results = test_multiple_images(counter, val_imgs, num_images=10)

# ============================================================================
# PART 10: TRAINING METRICS VISUALIZATION
# ============================================================================

print("\n" + "="*70)
print("üìà TRAINING METRICS & MODEL ANALYSIS")
print("="*70 + "\n")

results_path = 'parking_runs/parking_detector'

# Show training results
if os.path.exists(f'{results_path}/results.png'):
    img = plt.imread(f'{results_path}/results.png')
    plt.figure(figsize=(18, 11))
    plt.imshow(img)
    plt.axis('off')
    plt.title('YOLOv8 Training Progress - Loss Curves & Accuracy Metrics',
              fontsize=17, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()
    print("‚úì Training curves displayed")
else:
    print("‚ö†Ô∏è  Training results not found")

# Show confusion matrix
if os.path.exists(f'{results_path}/confusion_matrix.png'):
    img = plt.imread(f'{results_path}/confusion_matrix.png')
    plt.figure(figsize=(10, 9))
    plt.imshow(img)
    plt.axis('off')
    plt.title('Confusion Matrix - Prediction Accuracy',
              fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()
    print("‚úì Confusion matrix displayed")

# Show validation predictions
if os.path.exists(f'{results_path}/val_batch0_pred.jpg'):
    img = plt.imread(f'{results_path}/val_batch0_pred.jpg')
    plt.figure(figsize=(18, 13))
    plt.imshow(img)
    plt.axis('off')
    plt.title('Validation Set Predictions - Model Performance Overview',
              fontsize=17, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()
    print("‚úì Validation predictions displayed")

# ============================================================================
# FINAL PROJECT SUMMARY
# ============================================================================

print("\n" + "="*70)
print("‚úÖ SMART PARKING SPOT DETECTOR - PROJECT COMPLETE")
print("="*70)
print("\nüéØ Accomplishments:")
print("  ‚úì Trained YOLOv8 model on aerial parking lot images")
print("  ‚úì Achieved validation metrics (mAP, precision, recall)")
print("  ‚úì Built working car detection system")
print("  ‚úì Created automated parking spot counter")
print("  ‚úì Tested on 10+ validation images")
print("  ‚úì Generated comprehensive visualizations and statistics")
print("\nüìä All results displayed above in this notebook!")
print("üì∏ Screenshot any visualization for your presentation")
print("üíæ Model saved at: parking_runs/parking_detector/weights/best.pt")
print("="*70)

# Smart Parking Spot Detector - Complete Implementation
# Student: Kaden Glover | Course: ITAI 1378
# This code trains YOLOv8 to detect cars and count available parking spots

# ============================================================================
# PART 1: SETUP AND INSTALLATION
# ============================================================================

# Install required packages
!pip install -q ultralytics opencv-python pillow

# Import libraries
from ultralytics import YOLO
import cv2
import os
from pathlib import Path
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import torch

# Configure matplotlib for better display
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 100

# Check GPU availability
print("="*70)
print("SYSTEM CONFIGURATION")
print("="*70)
print(f"GPU Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU Device: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    DEVICE = 0
else:
    print("‚ö†Ô∏è  GPU not available - using CPU (training will be slower)")
    DEVICE = 'cpu'
print("="*70 + "\n")

# ============================================================================
# PART 2: DOWNLOAD AND SETUP DATASET
# ============================================================================

import kagglehub

print("üì• Downloading dataset from Kaggle...")
dataset_path = kagglehub.dataset_download('braunge/aerial-view-car-detection-for-yolov5')
print(f"‚úì Dataset downloaded to: {dataset_path}\n")

# Explore dataset structure
print("üìÇ Dataset Structure:")
for root, dirs, files in os.walk(dataset_path):
    level = root.replace(dataset_path, '').count(os.sep)
    if level < 3:  # Only show first 3 levels
        indent = '  ' * level
        folder_name = os.path.basename(root) or 'Root'
        print(f"{indent}üìÅ {folder_name}/")
        if level < 2:
            subindent = '  ' * (level + 1)
            img_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            txt_files = [f for f in files if f.lower().endswith('.txt')]
            if img_files:
                print(f"{subindent}üì∑ {len(img_files)} images")
            if txt_files:
                print(f"{subindent}üìù {len(txt_files)} labels")

DATASET_BASE = dataset_path

# ============================================================================
# PART 3: AUTO-DETECT DATASET PATHS
# ============================================================================

print("\nüîç Auto-detecting dataset paths...")

train_imgs = None
val_imgs = None

# Search for image folders
for root, dirs, files in os.walk(DATASET_BASE):
    for subdir in ['train', 'images/train', 'train/images']:
        check_path = os.path.join(root, subdir)
        if os.path.exists(check_path):
            img_files = [f for f in os.listdir(check_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            if len(img_files) > 0:
                train_imgs = check_path
                for val_name in ['val', 'valid', 'test']:
                    val_path = check_path.replace('train', val_name)
                    if os.path.exists(val_path):
                        val_imgs = val_path
                        break
                break
    if train_imgs:
        break

if train_imgs and val_imgs:
    train_count = len([f for f in os.listdir(train_imgs) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    val_count = len([f for f in os.listdir(val_imgs) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

    print(f"‚úì Training images: {train_imgs}")
    print(f"  ‚Üí {train_count} images")
    print(f"‚úì Validation images: {val_imgs}")
    print(f"  ‚Üí {val_count} images")

    train_labels = train_imgs.replace('images', 'labels')
    val_labels = val_imgs.replace('images', 'labels')

    if os.path.exists(train_labels):
        print(f"‚úì Training labels: {train_labels}")
    if os.path.exists(val_labels):
        print(f"‚úì Validation labels: {val_labels}")
else:
    raise Exception("Could not find dataset folders. Please check the dataset structure.")

# Create YAML configuration
data_yaml_content = f"""train: {train_imgs}
val: {val_imgs}

nc: 1
names: ['car']
"""

with open('mydata.yaml', 'w') as f:
    f.write(data_yaml_content)

print("\n‚úì Created mydata.yaml configuration\n")

# ============================================================================
# PART 4: VISUALIZE DATASET SAMPLES
# ============================================================================

def visualize_samples(image_folder, label_folder, num_samples=5):
    """Display sample images with bounding boxes"""

    image_files = list(Path(image_folder).glob('*'))[:num_samples]
    if not image_files:
        print(f"No images found in {image_folder}")
        return

    num_cols = min(len(image_files), num_samples)
    fig, axes = plt.subplots(1, num_cols, figsize=(5*num_cols, 5))
    if num_cols == 1:
        axes = [axes]

    for idx, img_path in enumerate(image_files):
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        label_path = Path(label_folder) / (img_path.stem + '.txt')

        if label_path.exists():
            with open(label_path, 'r') as f:
                lines = f.readlines()

            h, w = img.shape[:2]

            for line in lines:
                parts = line.strip().split()
                if len(parts) == 5:
                    _, x_center, y_center, width, height = map(float, parts)
                    x1 = int((x_center - width/2) * w)
                    y1 = int((y_center - height/2) * h)
                    x2 = int((x_center + width/2) * w)
                    y2 = int((y_center + height/2) * h)
                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)

        axes[idx].imshow(img)
        axes[idx].axis('off')
        axes[idx].set_title(f'Training Sample {idx+1}', fontsize=12, fontweight='bold')

    plt.suptitle('Dataset Samples with Ground Truth Labels', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.show()

print("="*70)
print("üì∏ DATASET VISUALIZATION")
print("="*70 + "\n")

if train_imgs and os.path.exists(train_imgs):
    train_labels_path = train_imgs.replace('images', 'labels')
    if os.path.exists(train_labels_path):
        visualize_samples(train_imgs, train_labels_path, num_samples=5)
    else:
        print(f"Label folder not found: {train_labels_path}")
else:
    print("Training images folder not found")

# ============================================================================
# PART 5: TRAIN YOLOV8 MODEL
# ============================================================================

def train_model(epochs=50, img_size=640, batch_size=16):
    """Train YOLOv8 model on parking dataset"""

    print("\n" + "="*70)
    print("üöÄ STARTING MODEL TRAINING")
    print("="*70)
    print(f"Configuration:")
    print(f"  ‚Ä¢ Model: YOLOv8 Nano (fastest)")
    print(f"  ‚Ä¢ Epochs: {epochs}")
    print(f"  ‚Ä¢ Image size: {img_size}x{img_size}")
    print(f"  ‚Ä¢ Batch size: {batch_size}")
    print(f"  ‚Ä¢ Device: {DEVICE}")
    print(f"  ‚Ä¢ Estimated time: 20-40 minutes on GPU")
    print("="*70 + "\n")

    model = YOLO('yolov8n.pt')

    results = model.train(
        data='mydata.yaml',
        epochs=epochs,
        imgsz=img_size,
        batch=batch_size,
        device=DEVICE,
        patience=10,
        save=True,
        project='parking_runs',
        name='parking_detector',
        exist_ok=True,
        verbose=True
    )

    print("\n" + "="*70)
    print("‚úÖ TRAINING COMPLETE!")
    print("="*70)
    print(f"Model saved: parking_runs/parking_detector/weights/best.pt")
    print("="*70 + "\n")

    return model

print("‚è≥ Training in progress... This will take 20-40 minutes")
trained_model = train_model(epochs=50, img_size=640, batch_size=16)

# ============================================================================
# PART 6: VALIDATE MODEL PERFORMANCE
# ============================================================================

def validate_model(model_path='parking_runs/parking_detector/weights/best.pt'):
    """Evaluate model on validation set"""

    print("\n" + "="*70)
    print("üìä VALIDATING MODEL PERFORMANCE")
    print("="*70 + "\n")

    model = YOLO(model_path)
    metrics = model.val(data='mydata.yaml')

    # Extract metrics safely
    map50 = float(metrics.box.map50) if hasattr(metrics.box.map50, '__float__') else float(metrics.box.map50.mean())
    map_overall = float(metrics.box.map) if hasattr(metrics.box.map, '__float__') else float(metrics.box.map.mean())
    precision = float(metrics.box.p) if hasattr(metrics.box.p, '__float__') else float(metrics.box.p.mean())
    recall = float(metrics.box.r) if hasattr(metrics.box.r, '__float__') else float(metrics.box.r.mean())

    print("PERFORMANCE METRICS")
    print("="*70)
    print(f"mAP@50:      {map50:.3f}  {'‚úÖ Excellent!' if map50 > 0.7 else '‚ö†Ô∏è  Good' if map50 > 0.6 else '‚ùå Needs work'}")
    print(f"mAP@50-95:   {map_overall:.3f}")
    print(f"Precision:   {precision:.3f}  (How accurate are detections)")
    print(f"Recall:      {recall:.3f}  (% of cars found)")
    print("="*70)

    if map50 > 0.70:
        print("\n‚úÖ EXCELLENT: Model exceeds target accuracy!")
    elif map50 > 0.60:
        print("\n‚ö†Ô∏è  GOOD: Model works well, consider more training for improvement")
    else:
        print("\n‚ùå NEEDS IMPROVEMENT: Try more epochs or data augmentation")

    print("="*70 + "\n")
    return metrics

validation_metrics = validate_model()

# ============================================================================
# PART 7: ADVANCED PARKING SPOT COUNTER WITH GRID DETECTION
# ============================================================================

class ParkingSpotCounter:
    """Detects cars and calculates available parking spots with grid-based detection"""

    def __init__(self, model_path, total_spots=50, grid_rows=5, grid_cols=10):
        self.model = YOLO(model_path)
        self.total_spots = total_spots
        self.grid_rows = grid_rows
        self.grid_cols = grid_cols
        print(f"‚úì Parking counter initialized")
        print(f"  ‚Üí Total spots: {total_spots}")
        print(f"  ‚Üí Grid layout: {grid_rows}x{grid_cols}")

    def detect_cars(self, image_path, conf_threshold=0.5):
        """Detect cars in an image"""
        results = self.model(image_path, conf=conf_threshold, verbose=False)
        car_count = len(results[0].boxes)
        return results, car_count

    def calculate_available_spots(self, car_count):
        """Calculate available parking spots"""
        return max(0, self.total_spots - car_count)

    def create_parking_grid(self, img_shape):
        """Create a grid representing parking spaces"""
        h, w = img_shape[:2]
        cell_h = h // self.grid_rows
        cell_w = w // self.grid_cols

        grid_spots = []
        for row in range(self.grid_rows):
            for col in range(self.grid_cols):
                x1 = col * cell_w
                y1 = row * cell_h
                x2 = x1 + cell_w
                y2 = y1 + cell_h
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2
                grid_spots.append({
                    'id': row * self.grid_cols + col + 1,
                    'bbox': (x1, y1, x2, y2),
                    'center': (center_x, center_y),
                    'occupied': False
                })

        return grid_spots

    def check_spot_occupancy(self, grid_spots, detections):
        """Check which parking spots are occupied based on car detections"""

        for detection in detections:
            # Get detection bounding box
            x1, y1, x2, y2 = map(int, detection[:4])
            det_center_x = (x1 + x2) // 2
            det_center_y = (y1 + y2) // 2

            # Find closest grid spot
            min_dist = float('inf')
            closest_spot = None

            for spot in grid_spots:
                spot_cx, spot_cy = spot['center']
                dist = np.sqrt((det_center_x - spot_cx)**2 + (det_center_y - spot_cy)**2)

                if dist < min_dist:
                    min_dist = dist
                    closest_spot = spot

            # Mark spot as occupied if detection is close enough
            if closest_spot and min_dist < (closest_spot['bbox'][2] - closest_spot['bbox'][0]) * 0.8:
                closest_spot['occupied'] = True

        return grid_spots

    def visualize_detection(self, image_path, conf_threshold=0.5, show_grid=True):
        """Detect cars and visualize results with parking grid"""

        # Read image
        img = cv2.imread(image_path)
        img_display = img.copy()

        # Run detection
        results, car_count = self.detect_cars(image_path, conf_threshold)

        # Get detections
        boxes = results[0].boxes
        detections = boxes.xyxy.cpu().numpy() if len(boxes) > 0 else []

        # Create parking grid
        grid_spots = self.create_parking_grid(img.shape)

        # Check occupancy
        if len(detections) > 0:
            grid_spots = self.check_spot_occupancy(grid_spots, detections)

        # Count available spots
        occupied_count = sum(1 for spot in grid_spots if spot['occupied'])
        available_count = len(grid_spots) - occupied_count

        # Draw parking grid and status
        for spot in grid_spots:
            x1, y1, x2, y2 = spot['bbox']

            if show_grid:
                # Draw grid lines
                cv2.rectangle(img_display, (x1, y1), (x2, y2), (100, 100, 100), 1)

            # Color code: Green = available, Red = occupied
            if spot['occupied']:
                # Draw red overlay for occupied
                overlay = img_display.copy()
                cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 255), -1)
                cv2.addWeighted(overlay, 0.3, img_display, 0.7, 0, img_display)
                cv2.rectangle(img_display, (x1, y1), (x2, y2), (0, 0, 255), 2)

                # Add "X" mark
                cv2.line(img_display, (x1+5, y1+5), (x2-5, y2-5), (0, 0, 255), 2)
                cv2.line(img_display, (x2-5, y1+5), (x1+5, y2-5), (0, 0, 255), 2)
            else:
                # Draw green overlay for available
                overlay = img_display.copy()
                cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), -1)
                cv2.addWeighted(overlay, 0.2, img_display, 0.8, 0, img_display)
                cv2.rectangle(img_display, (x1, y1), (x2, y2), (0, 255, 0), 2)

                # Add checkmark
                cx, cy = spot['center']
                cv2.putText(img_display, "‚úì", (cx-10, cy+10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # Draw detected cars with bounding boxes
        for detection in detections:
            x1, y1, x2, y2 = map(int, detection[:4])
            cv2.rectangle(img_display, (x1, y1), (x2, y2), (255, 255, 0), 3)
            cv2.putText(img_display, "CAR", (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        # Add professional info panel
        h, w = img_display.shape[:2]
        panel_height = 140
        overlay = img_display.copy()
        cv2.rectangle(overlay, (10, 10), (500, panel_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, img_display, 0.3, 0, img_display)

        cv2.rectangle(img_display, (10, 10), (500, panel_height), (255, 255, 255), 3)

        # Add text information
        cv2.putText(img_display, f"Cars Detected: {car_count}",
                    (25, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
        cv2.putText(img_display, f"Occupied: {occupied_count} spots",
                    (25, 85), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
        cv2.putText(img_display, f"Available: {available_count} spots",
                    (25, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)

        # Add legend
        legend_x = w - 200
        legend_y = 30
        cv2.rectangle(img_display, (legend_x, legend_y), (legend_x+180, legend_y+80), (0, 0, 0), -1)
        cv2.rectangle(img_display, (legend_x, legend_y), (legend_x+180, legend_y+80), (255, 255, 255), 2)

        cv2.rectangle(img_display, (legend_x+10, legend_y+15), (legend_x+35, legend_y+35), (0, 255, 0), -1)
        cv2.putText(img_display, "Available", (legend_x+45, legend_y+30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        cv2.rectangle(img_display, (legend_x+10, legend_y+50), (legend_x+35, legend_y+70), (0, 0, 255), -1)
        cv2.putText(img_display, "Occupied", (legend_x+45, legend_y+65),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # Display
        plt.figure(figsize=(16, 12))
        plt.imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        title = f"Smart Parking Detection: {car_count} Cars | {available_count}/{len(grid_spots)} Spots Available"
        plt.title(title, fontsize=17, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.show()

        occupancy_rate = (occupied_count / len(grid_spots)) * 100

        return {
            'cars_detected': car_count,
            'occupied_spots': occupied_count,
            'available_spots': available_count,
            'total_spots': len(grid_spots),
            'occupancy_rate': occupancy_rate,
            'grid_spots': grid_spots
        }

# ============================================================================
# PART 8: TEST ON SINGLE IMAGE
# ============================================================================

print("="*70)
print("üß™ TESTING THE PARKING DETECTOR")
print("="*70 + "\n")

counter = ParkingSpotCounter(
    model_path='parking_runs/parking_detector/weights/best.pt',
    total_spots=50
)

if val_imgs and os.path.exists(val_imgs):
    val_image_files = list(Path(val_imgs).glob('*'))
    if val_image_files:
        test_image = str(val_image_files[0])
        print(f"Testing on: {Path(test_image).name}\n")

        results = counter.visualize_detection(test_image, conf_threshold=0.5)

        print("\n" + "="*70)
        print("PARKING LOT STATUS")
        print("="*70)
        print(f"üöó Cars Detected:     {results['cars_detected']}")
        print(f"üÖøÔ∏è  Available Spots:   {results['available_spots']}")
        print(f"üìä Total Capacity:    {results['total_spots']}")
        print(f"üìà Occupancy Rate:    {results['occupancy_rate']:.1f}%")
        print("="*70 + "\n")

# ============================================================================
# PART 9: BATCH TESTING WITH VISUALIZATIONS
# ============================================================================

def test_multiple_images(counter, image_folder, num_images=10):
    """Test detector on multiple images and show comprehensive results"""

    image_files = list(Path(image_folder).glob('*'))[:num_images]

    if not image_files:
        print(f"No images found in {image_folder}")
        return []

    print("\n" + "="*70)
    print(f"üì∏ BATCH TESTING ON {len(image_files)} IMAGES")
    print("="*70 + "\n")

    all_results = []

    for idx, img_path in enumerate(image_files, 1):
        print(f"\n{'='*70}")
        print(f"IMAGE {idx}/{len(image_files)}: {img_path.name}")
        print('='*70)

        results = counter.visualize_detection(str(img_path))

        print(f"\nüìä Results:")
        print(f"   üöó Cars: {results['cars_detected']}")
        print(f"   üÖøÔ∏è  Available: {results['available_spots']}")
        print(f"   üìà Occupancy: {results['occupancy_rate']:.1f}%")

        all_results.append(results)

    # Summary statistics
    print("\n" + "="*70)
    print("üìä BATCH TESTING SUMMARY")
    print("="*70)

    total_cars = sum(r['cars_detected'] for r in all_results)
    avg_occupancy = sum(r['occupancy_rate'] for r in all_results) / len(all_results)
    min_cars = min(r['cars_detected'] for r in all_results)
    max_cars = max(r['cars_detected'] for r in all_results)

    print(f"Images Tested:        {len(image_files)}")
    print(f"Total Cars Found:     {total_cars}")
    print(f"Average Occupancy:    {avg_occupancy:.1f}%")
    print(f"Range:                {min_cars} - {max_cars} cars per image")
    print("="*70 + "\n")

    # Create summary charts
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # Cars detected chart
    car_counts = [r['cars_detected'] for r in all_results]
    colors1 = ['#2E86AB' if c < 35 else '#A23B72' if c < 45 else '#F18F01' for c in car_counts]
    ax1.bar(range(1, len(car_counts)+1), car_counts, color=colors1, edgecolor='black', linewidth=1.5)
    ax1.set_xlabel('Image Number', fontsize=13, fontweight='bold')
    ax1.set_ylabel('Cars Detected', fontsize=13, fontweight='bold')
    ax1.set_title('Cars Detected Per Image', fontsize=15, fontweight='bold', pad=15)
    ax1.grid(axis='y', alpha=0.3, linestyle='--')
    ax1.set_axisbelow(True)

    # Occupancy rate chart
    occupancy_rates = [r['occupancy_rate'] for r in all_results]
    colors2 = ['#06A77D' if o < 70 else '#F4B942' if o < 90 else '#D62246' for o in occupancy_rates]
    ax2.bar(range(1, len(occupancy_rates)+1), occupancy_rates, color=colors2, edgecolor='black', linewidth=1.5)
    ax2.set_xlabel('Image Number', fontsize=13, fontweight='bold')
    ax2.set_ylabel('Occupancy Rate (%)', fontsize=13, fontweight='bold')
    ax2.set_title('Parking Lot Occupancy Analysis', fontsize=15, fontweight='bold', pad=15)
    ax2.axhline(y=70, color='#F4B942', linestyle='--', linewidth=2, label='70% Capacity', alpha=0.7)
    ax2.axhline(y=90, color='#D62246', linestyle='--', linewidth=2, label='90% Full', alpha=0.7)
    ax2.legend(fontsize=11)
    ax2.grid(axis='y', alpha=0.3, linestyle='--')
    ax2.set_axisbelow(True)
    ax2.set_ylim(0, 100)

    plt.tight_layout()
    plt.show()

    return all_results

if val_imgs and os.path.exists(val_imgs):
    test_results = test_multiple_images(counter, val_imgs, num_images=10)

# ============================================================================
# PART 10: TRAINING METRICS VISUALIZATION
# ============================================================================

print("\n" + "="*70)
print("üìà TRAINING METRICS & MODEL ANALYSIS")
print("="*70 + "\n")

results_path = 'parking_runs/parking_detector'

# Show training results
if os.path.exists(f'{results_path}/results.png'):
    img = plt.imread(f'{results_path}/results.png')
    plt.figure(figsize=(18, 11))
    plt.imshow(img)
    plt.axis('off')
    plt.title('YOLOv8 Training Progress - Loss Curves & Accuracy Metrics',
              fontsize=17, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()
    print("‚úì Training curves displayed")
else:
    print("‚ö†Ô∏è  Training results not found")

# Show confusion matrix
if os.path.exists(f'{results_path}/confusion_matrix.png'):
    img = plt.imread(f'{results_path}/confusion_matrix.png')
    plt.figure(figsize=(10, 9))
    plt.imshow(img)
    plt.axis('off')
    plt.title('Confusion Matrix - Prediction Accuracy',
              fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()
    print("‚úì Confusion matrix displayed")

# Show validation predictions
if os.path.exists(f'{results_path}/val_batch0_pred.jpg'):
    img = plt.imread(f'{results_path}/val_batch0_pred.jpg')
    plt.figure(figsize=(18, 13))
    plt.imshow(img)
    plt.axis('off')
    plt.title('Validation Set Predictions - Model Performance Overview',
              fontsize=17, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()
    print("‚úì Validation predictions displayed")

# ============================================================================
# FINAL PROJECT SUMMARY
# ============================================================================

print("\n" + "="*70)
print("‚úÖ SMART PARKING SPOT DETECTOR - PROJECT COMPLETE")
print("="*70)
print("\nüéØ Accomplishments:")
print("  ‚úì Trained YOLOv8 model on aerial parking lot images")
print("  ‚úì Achieved validation metrics (mAP, precision, recall)")
print("  ‚úì Built working car detection system")
print("  ‚úì Created automated parking spot counter")
print("  ‚úì Tested on 10+ validation images")
print("  ‚úì Generated comprehensive visualizations and statistics")
print("\nüìä All results displayed above in this notebook!")
print("üì∏ Screenshot any visualization for your presentation")
print("üíæ Model saved at: parking_runs/parking_detector/weights/best.pt")
print("="*70)